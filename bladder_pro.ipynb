{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/chencancan/Desktop/jiang_prognosis\n"
     ]
    }
   ],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of data is (192912, 16)\n",
      "192912\n"
     ]
    }
   ],
   "source": [
    "# data = pd.read_csv('bladder_cancer.csv',encoding='ISO-8859-1')\n",
    "# data.iloc[0,:-2]\n",
    "# print('the shape of data is {}'.format(data.shape))\n",
    "# all_data_dict = dict()\n",
    "# for i in range(data.shape[0]):\n",
    "# # for i in range(2):\n",
    "#     all_data_dict[str(i)] = data.iloc[i,:-2].values.tolist()\n",
    "# #     print(data.iloc[0,:-2].values.tolist())\n",
    "# #     print(len(data.iloc[0,:-2].values.tolist()))\n",
    "# #     print(all_data_dict)\n",
    "# print(len(all_data_dict.keys()))\n",
    "\n",
    "# f = open('all_data.pl','wb')\n",
    "# pickle.dump(all_data_dict, f)\n",
    "# f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "['White', 'Female', 62, 'Grade 1', 'Left', 'ccRCC', 'M0', 'N0', 'T1a', 'Radical', '26', 77, 'Alive', 'Married']\n"
     ]
    }
   ],
   "source": [
    "### Select the data which have the precise tumor size\n",
    "# selected_dict = dict()\n",
    "# keys = list(all_data_dict.keys())\n",
    "# # print(keys)\n",
    "# column_number= len(all_data_dict[keys[0]])\n",
    "# print(column_number)\n",
    "# print(all_data_dict[keys[1]])\n",
    "# for i in np.arange(len(keys)):\n",
    "#     if all_data_dict[keys[i]][10] != 'unknown':\n",
    "# #         print(all_data_dict[keys[i]][10])\n",
    "#         selected_dict[keys[i]] = all_data_dict[keys[i]]\n",
    "#     elif all_data_dict[keys[i]][10] == 'unknown':\n",
    "#         continue\n",
    "#     else:\n",
    "#         raise ValueError\n",
    "# print(selected_dict)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = open('selected_data.pl','wb')\n",
    "# pickle.dump(selected_dict, f)\n",
    "# f.close()\n",
    "# frame = pd.DataFrame(selected_dict)\n",
    "# frame = frame.T\n",
    "# frame.to_csv('selected.csv', index=None, header=None, encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### Find the categories of each features in our data\n",
    "f = open('selected_data.pl','rb')\n",
    "selected_dict = pickle.load(f)\n",
    "f.close()\n",
    "keys = list(selected_dict.keys())\n",
    "column_number= len(selected_dict[keys[0]])\n",
    "columns = list()\n",
    "for index in range(column_number):\n",
    "    temp = list()\n",
    "    for  key in keys:\n",
    "#         print(selected_dict[key][index])\n",
    "        temp.append(selected_dict[key][index])\n",
    "    temp = list(set(temp))\n",
    "    columns.append(temp)\n",
    "#     print(columns[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "###The target dict containing the weight value of each features\n",
    "# target = dict()\n",
    "# target['Race'] = list([['Black', 1], ['White',2],  ['Other', 3]])\n",
    "# target['Sex'] = list([['Female', 1],  ['Male', 2]])\n",
    "# target['Tumor Grade'] = list([['Grade 1', 1], ['Grade 2', 2], ['Grade 3', 3], ['Grade 4', 4]])\n",
    "# target['Side'] = list([['Left',1],['Right',2], ['Bilateral',3]] )\n",
    "# target['Pathology Type'] = list([['ccRCC', 1],  ['pRCC',2], ['chRCC',3], ['MixedRCC',4], ['CollRCC',5], ['MeduRCC',6], \n",
    "#                                  ['sarcoRCC',7],['CystRCC',8],['GranuRCC',9], ['AcidRCC',10], ['others', 11]])\n",
    "# target['M stage'] = list([['MX', 1],  ['M0',2], ['M1', 3]])\n",
    "# target['N stage'] = list([['NX',1], ['N0',2], ['N1', 3] ])\n",
    "# target['T stage'] = list([['TX',1], ['T1a',2], ['T1b',2], ['T2', 3], ['T3NOS',4], ['T3a',4], ['T3b',4], ['T3c',4], ['T4',5]])\n",
    "# target['Surgery'] = list([['No surgery',1], ['Partial',2], ['Radical',3], ['Local therapy',4], ['Surgery with unknown method',5]])\n",
    "# target['Married status'] = list([['Married',1], ['Unmarried',2]])\n",
    "# target['Overall survival status'] = list([['Alive',0],['Dead',1]])\n",
    "# f = open('target.pickle','wb')\n",
    "# pickle.dump(target, f)\n",
    "# f.close()\n",
    "f = open('target.pickle','rb')\n",
    "target = pickle.load(f)\n",
    "f.close()\n",
    "# target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Race', 'Sex', 'Tumor Grade', 'Side', 'Pathology Type', 'M stage', 'N stage', 'T stage', 'Surgery', 'Married status', 'Overall survival status'])\n",
      "['White', 'Female', 62, 'Grade 1', 'Left', 'ccRCC', 'M0', 'N0', 'T1a', 'Radical', '26', 77, 'Alive', 'Married']\n"
     ]
    }
   ],
   "source": [
    "print(target.keys())\n",
    "print(selected_dict[list(selected_dict.keys())[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120202\n"
     ]
    }
   ],
   "source": [
    "####the process of category to real value \n",
    "# keys = list(selected_dict.keys())\n",
    "# pfeatures = list(['Race', 'Sex', 'Age', 'Tumor Grade', 'Side', 'Pathology Type', 'M stage', \n",
    "#                  'N stage', 'T stage', 'Surgery', 'Tumor size', 'Survival time','Overall survival status', 'Married status'])\n",
    "# selected_value = dict()\n",
    "# for key in keys:\n",
    "#     temp = list()\n",
    "#     row = selected_dict[key]\n",
    "#     print('the processing patient is ', key)\n",
    "#     for i in np.arange(len(row)):\n",
    "#         feature = pfeatures[i]\n",
    "# #         print(feature)\n",
    "# #         print('the processing category is ', row[i])\n",
    "#         if feature in list(['Age', 'Tumor size', 'Survival time']):\n",
    "#             if row[i] in list(['unknown', 'Unknown']):\n",
    "#                 temp.append(np.nan)\n",
    "#             elif isinstance(int(row[i]), int):\n",
    "#                 temp.append(int(row[i]))\n",
    "#             else:\n",
    "#                 print('the wrong feature value of patient {}  is {} !!!'.format(key, row[i]))\n",
    "#                 raise ValueError('')\n",
    "#         elif feature in list(set(pfeatures)-set(list(['Age', 'Tumor size', 'Survival time']))):\n",
    "#             fcategory = [s[0] for s in target[feature]]\n",
    "# #             print(fcategory)\n",
    "#             if row[i] in list(['unknown', 'Unknown']):\n",
    "#                 temp.append(np.nan)\n",
    "#             elif row[i] in list(fcategory):\n",
    "#                 for index in range(len(fcategory)):\n",
    "#                     if row[i] == target[feature][index][0]:\n",
    "#                         temp.append(int(target[feature][index][1]))\n",
    "#                         break\n",
    "#             else:\n",
    "#                 raise ValueError('the wrong feature value of patient {}  is {} !!!'.format(key, row[i]))\n",
    "#     assert len(row) == len(temp), 'the process of category to real value is wrong!!'\n",
    "#     selected_value[key] = temp\n",
    "# print(len(selected_value.keys()))\n",
    "# f = open('selected_value.pickle','wb')\n",
    "# pickle.dump(selected_value, f)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120202\n",
      "[2, 1, 62, 1, 1, 1, 2, 2, 2, 3, 26, 77, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "###convert pickle data into csv data\n",
    "f = open('selected_value.pickle','rb')\n",
    "selected_value = pickle.load(f)\n",
    "f.close()\n",
    "print(len(selected_value.keys()))\n",
    "print(selected_value['1'])\n",
    "\n",
    "pfeatures = list(['Race', 'Sex', 'Age', 'Tumor_Grade', 'Side', 'Pathology_Type', 'M_stage', \n",
    "                 'N_stage', 'T_stage', 'Surgery', 'Tumor_size', 'Survival_time', 'Married_status','Overall_survival_status'])\n",
    "f = open('selected_value.csv', 'w', encoding='utf8')\n",
    "csv_writer = csv.writer(f)\n",
    "csv_writer.writerow(pfeatures)\n",
    "for key in selected_value.keys():\n",
    "    temp = selected_value[key][:-2]\n",
    "    temp.append(selected_value[key][-1])\n",
    "    temp.append(selected_value[key][-2])\n",
    "    assert len(temp) == len(pfeatures), 'the category setting is wrong!'\n",
    "    csv_writer.writerow(temp)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of NaN in the column Race is 793 \n",
      "the number of NaN in the column Sex is 0 \n",
      "the number of NaN in the column Age is 0 \n",
      "the number of NaN in the column Tumor_Grade is 22279 \n",
      "the number of NaN in the column Side is 28 \n",
      "the number of NaN in the column Pathology_Type is 411 \n",
      "the number of NaN in the column M_stage is 677 \n",
      "the number of NaN in the column N_stage is 677 \n",
      "the number of NaN in the column T_stage is 677 \n",
      "the number of NaN in the column Surgery is 54 \n",
      "the number of NaN in the column Tumor_size is 0 \n",
      "the number of NaN in the column Survival_time is 0 \n",
      "the number of NaN in the column Married_status is 5612 \n",
      "the number of NaN in the column Overall_survival_status is 0 \n"
     ]
    }
   ],
   "source": [
    "### statistic the number of NaN in each columns\n",
    "data = pd.read_csv('selected_value.csv', encoding='utf8')\n",
    "columns = data.columns.tolist()\n",
    "import math\n",
    "for col in columns:\n",
    "    temp = data.loc[:, col].tolist()\n",
    "    nan_num = 0\n",
    "    for t in temp:\n",
    "        if math.isnan(t):\n",
    "            nan_num += 1\n",
    "    print('the number of NaN in the column {} is {} '.format(col, nan_num))\n",
    "\n",
    "### selected the patients without unknown data which do not need to be interpolated by missing value\n",
    "f = open('unmissing_data.csv', 'w', encoding='utf8')\n",
    "csv_writer = csv.writer(f)\n",
    "csv_writer.writerow(pfeatures)\n",
    "for i in np.arange(data.shape[0]):\n",
    "    temp = data.iloc[i,:].tolist()\n",
    "    need = True\n",
    "    for t in temp:\n",
    "        if math.isnan(t):\n",
    "            need = False\n",
    "    if need:\n",
    "        csv_writer.writerow(temp)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "class MachineLearning():\n",
    "    def __init__(self, modelname=None):\n",
    "        self._modelname = modelname\n",
    "    def dismatch(self, *args, **kwgs):\n",
    "#     def dismatch(self):\n",
    "        try:\n",
    "            getattr(self, 'select_{}'.format(self._modelname))\n",
    "        except AttributeError as error:\n",
    "            self._modelname = \"\"\n",
    "        finally:\n",
    "            pass\n",
    "        return getattr(self, 'select_{}'.format(self._modelname))(*args, **kwgs)\n",
    "    def select_svm(self):\n",
    "        return sklearn.svm.SVC(gamma='auto')\n",
    "    def select_bayes(self):\n",
    "        return sklearn.naive_bayes.GaussianNB()\n",
    "    def select_decision_tree(self):\n",
    "        return sklearn.tree.DecisionTreeClassifier()\n",
    "    def select_random_forest(self):\n",
    "        return sklearn.ensemble.RandomForestClassifier(n_estimators=1000, max_depth=None, min_samples_split=10, random_state=0)\n",
    "    def select_neutral_network(self):\n",
    "        return sklearn.neutral_network.MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(100, 50), random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the  shape of our data is  (92475, 14)\n",
      "73980 73980\n",
      "18495 18495\n",
      "Start to train model:  svm\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "data = pd.read_csv('unmissing_data4.csv', encoding='utf8')\n",
    "height, weight = data.shape\n",
    "print('the  shape of our data is ', data.shape)\n",
    "# columns = data.columns.tolist()\n",
    "train_x = data.iloc[:int(height*0.8), :-1]; train_y = data.iloc[:int(height*0.8), -1].tolist()\n",
    "test_x = data.iloc[int(height*0.8):, :-1]; test_y = data.iloc[int(height*0.8):, -1].tolist()\n",
    "print(len(train_x), len(train_y))\n",
    "print(len(test_x), len(test_y))\n",
    "\n",
    "assert len(train_x) == len(train_y)\n",
    "assert len(test_x) == len(test_y)\n",
    "\n",
    "modelname = ['svm', 'bayes', 'decision_tree', 'random_forest', 'neutral_network']\n",
    "for index in range(len(modelname)):\n",
    "    print('Start to train model: ', modelname[index])\n",
    "    ml = MachineLearning(modelname[index])\n",
    "    model = ml.dismatch()\n",
    "#     train_x = np.array(train_x); train_y = np.array(train_y); test_x=np.array(test_x); test_y=np.array(test_y)\n",
    "#     print(train_x[0])\n",
    "#     print(type(train_x[0][0]), type(train_y[0]))\n",
    "    clf = model.fit(train_x, train_y)\n",
    "    pred_y = clf.predict(test_x)\n",
    "    accuracy = metrics.accuracy_score(test_y, pred_y, normalize=True)\n",
    "    print('The accuracy of the current model {} is {}!'.format(modelname[index], accuracy))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
